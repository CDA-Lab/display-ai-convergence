{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## MaxwellFDFD Data download\n",
    "1. download data from link\n",
    "2. make directory\n",
    "3. unzip dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!curl -L -o maxwellfdfd.zip https://drive.google.com/uc?id=14-Bl89OzRtLM1MCW2H81Xvivq8EvTrmB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir maxwellfdfd\n",
    "!unzip maxwellfdfd.zip -d ./maxwellfdfd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN model for multi-output regression\n",
    "1. 4 layer\n",
    "2. Adam\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from typing import Any, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def compress_image(prev_image, n):\n",
    "    if n < 2:\n",
    "        return prev_image\n",
    "\n",
    "    height = prev_image.shape[0] // n\n",
    "    width = prev_image.shape[1] // n\n",
    "    new_image = np.zeros((height, width), dtype=\"uint8\")\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            new_image[i, j] = prev_image[n * i, n * j]\n",
    "\n",
    "    return new_image\n",
    "\n",
    "class CEMDataset(torch.utils.data.Dataset):\n",
    "    DATASETS_TRAIN = [\n",
    "        'binary_501',\n",
    "        'binary_502',\n",
    "        'binary_503',\n",
    "        'binary_504',\n",
    "        'binary_505',\n",
    "        'binary_506',\n",
    "        'binary_507',\n",
    "        'binary_508',\n",
    "        'binary_509',\n",
    "        'binary_510',\n",
    "        'binary_511',\n",
    "        'binary_512',\n",
    "        'binary_1001',\n",
    "        'binary_1002',\n",
    "        'binary_1003',\n",
    "        # 'binary_rl_fix_501',\n",
    "        # 'binary_rl_fix_502',\n",
    "        # 'binary_rl_fix_503',\n",
    "        # 'binary_rl_fix_504',\n",
    "        # 'binary_rl_fix_505',\n",
    "        # 'binary_rl_fix_506',\n",
    "        # 'binary_rl_fix_507',\n",
    "        # 'binary_rl_fix_508',\n",
    "        # 'binary_rl_fix_509',\n",
    "        # 'binary_rl_fix_510',\n",
    "        # 'binary_rl_fix_511',\n",
    "        # 'binary_rl_fix_512',\n",
    "        # 'binary_rl_fix_513',\n",
    "        # 'binary_rl_fix_514',\n",
    "        # 'binary_rl_fix_515',\n",
    "        # 'binary_rl_fix_516',\n",
    "        # 'binary_rl_fix_517',\n",
    "        # 'binary_rl_fix_518',\n",
    "        # 'binary_rl_fix_519',\n",
    "        # 'binary_rl_fix_520',\n",
    "        # 'binary_rl_fix_1001',\n",
    "        # 'binary_rl_fix_1002',\n",
    "        # 'binary_rl_fix_1003',\n",
    "        # 'binary_rl_fix_1004',\n",
    "        # 'binary_rl_fix_1005',\n",
    "        # 'binary_rl_fix_1006',\n",
    "        # 'binary_rl_fix_1007',\n",
    "        # 'binary_rl_fix_1008',\n",
    "    ]\n",
    "\n",
    "    DATASETS_VALID = [\n",
    "        'binary_1004',\n",
    "        'binary_test_1001',\n",
    "        'binary_test_1002',\n",
    "        'binary_rl_fix_1009',\n",
    "        'binary_rl_fix_1010',\n",
    "        'binary_rl_fix_1011',\n",
    "        'binary_rl_fix_1012',\n",
    "        'binary_rl_fix_1013',\n",
    "        'binary_rl_fix_test_1001',\n",
    "    ]\n",
    "\n",
    "    DATASETS_TEST = [\n",
    "        'binary_new_test_501',\n",
    "        'binary_new_test_1501',\n",
    "        # 'binary_rl_fix_1014',\n",
    "        # 'binary_rl_fix_1015',\n",
    "        # 'binary_rl_fix_test_1002',\n",
    "        # 'binary_rl_fix_test_1003',\n",
    "        # 'binary_rl_fix_test_1004',\n",
    "        # 'binary_rl_fix_test_1005',\n",
    "        'binary_test_1101',\n",
    "    ]\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                train: str = 'train',\n",
    "                scale: int = 1,\n",
    "                 ) -> None:\n",
    "        self.train = train\n",
    "        self.root = root\n",
    "        self.scale = scale\n",
    "        self.width = 200 // scale\n",
    "        self.height = 100 // scale\n",
    "\n",
    "        if self.train == 'train':\n",
    "            DATAPATH = os.path.join(root, 'train')\n",
    "            DATASETS = self.DATASETS_TRAIN\n",
    "        elif self.train == 'valid':\n",
    "            DATAPATH = os.path.join(root, 'valid')\n",
    "            DATASETS = self.DATASETS_VALID\n",
    "        else:\n",
    "            DATAPATH = os.path.join(root, 'test')\n",
    "            DATASETS = self.DATASETS_TEST\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "\n",
    "        print('data loading ... ')\n",
    "\n",
    "        # load Train dataset\n",
    "        for data in DATASETS:\n",
    "            dataframe = pd.read_csv(os.path.join(DATAPATH, '{}.csv'.format(data)), delim_whitespace=False, header=None)\n",
    "            dataset = dataframe.values\n",
    "\n",
    "            # split into input (X) and output (Y) variables\n",
    "            fileNames = dataset[:, 0]\n",
    "\n",
    "            # 1. first try max\n",
    "            dataset[:, 1:25] /= 2767.1\n",
    "            self.targets.extend(dataset[:, 1:25])\n",
    "            for idx, file in enumerate(fileNames):\n",
    "                try:\n",
    "                    image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(int(file))))\n",
    "                    image = np.array(image).astype(np.uint8)\n",
    "                except (TypeError, FileNotFoundError) as te:\n",
    "                    image = Image.open(os.path.join(DATAPATH, data, '{}.tiff'.format(idx + 1)))\n",
    "                    try:\n",
    "                        image = np.array(image).astype(np.uint8)\n",
    "                    except:\n",
    "                        continue\n",
    "                image = compress_image(image, self.scale)\n",
    "                self.data.append(np.array(image).flatten(order='C'))\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 1, self.height, self.width)\n",
    "        self.data = self.data.transpose((0, 1, 2, 3))  # convert to HWC CHW\n",
    "        print(f'Data Loading Finished. len : {len(self.data)}')\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'maxwellfdfd')\n",
    "data_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cem_train = CEMDataset(data_dir, train='train', scale=5)\n",
    "cem_valid = CEMDataset(data_dir, train='test', scale=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(cem_train, batch_size, shuffle=True, pin_memory=True)\n",
    "val_dl = DataLoader(cem_valid, batch_size, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * 1.\n",
    "\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    s = make_grid(images.detach()[:nmax], nrow=8)\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8, padding=5, pad_value=0.5).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dl, nmax=64):\n",
    "    for images, _ in dl:\n",
    "        show_images(images, nmax)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using a GPU\n",
    "\n",
    "To seamlessly use a GPU, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the GPU, if one is available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Refer to [Sylvian's post](https://sgugger.github.io/convolution-in-depth.html) for an explanation of `kernel_size`, `stride` and `padding`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_device(simple_model, device)\n",
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = simple_model(images.float())\n",
    "    print('out.shape:', out.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `Conv2d` layer transforms a 3-channel image to a 16-channel *feature map*, and the `MaxPool2d` layer halves the height and width. The feature map gets smaller as we add more layers, until we are finally left with a small feature map, which can be flattened into a vector. We can then add some fully connected layers at the end to get vector of size 10 for each image.\n",
    "\n",
    "<img src=\"https://i.imgur.com/KKtPOKE.png\" style=\"max-width:540px\">\n",
    "\n",
    "Let's define the model by extending an `ImageClassificationBase` class which contains helper methods for training & validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images.float())                  # Generate predictions\n",
    "        loss = F.l1_loss(out, labels)\n",
    "        # loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images.float())                    # Generate predictions\n",
    "        loss = F.l1_loss(out, labels)\n",
    "        # loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        r2 = rsquare(out, labels)           # Calculate r2\n",
    "        return {'val_loss': loss.detach(), 'val_acc': r2}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "def rsquare(outputs, labels):\n",
    "    pred = outputs.cpu().data.numpy()\n",
    "    pred = pred.reshape(-1, pred.shape[1])\n",
    "    real = labels.cpu().numpy()\n",
    "    result = r2_score(pred,  real)\n",
    "    return torch.tensor(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            # in: 1 x 20 x 40\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            # out: 1 x 1 x 1\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1600, 24),\n",
    "            nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CnnModel()\n",
    "to_device(model, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's verify that the model produces the expected output on a batch of training data. The 24 outputs for each image can be interpreted as transmittance for the 24 target classes (after applying sigmoid)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model(images.float())\n",
    "    print('out.shape:', out.shape)\n",
    "    print('out[0]:', out[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll define two functions: `fit` and `evaluate` to train the model using gradient descent and evaluate its performance on the validation set. For a detailed walkthrough of these functions, check out the [previous tutorial](https://jovian.ai/aakashns/03-logistic-regression)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we begin training, let's instantiate the model once again and see how it performs on the validation set with the initial set of parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = to_device(CnnModel(), device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(model, val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n",
    "\n",
    "We'll use the following *hyperparmeters* (learning rate, no. of epochs, batch_size etc.) to train our model. As an exercise, you can try changing these to see if you have achieve a higher accuracy in a shorter time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_accuracies(history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_losses(history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}